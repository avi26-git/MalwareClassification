{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this term project is to demonstrate your practical skills in implementing and deploying machine learning models for malware classification. The technical implementation of this project is comprised of three main tasks that need to be completed sequentially:\n",
    "\n",
    "Task 1 - Training: In this task, you will be creating and training a deep neural network based on the MalConv architecture to classify PE files as malware or benign. As for the dataset, you will be using the EMBER-2017 v2 ( https://github.com/endgameinc/ember ).\n",
    "\n",
    "If you explore the EMBER repository, you will find that it comes with a sample implementation of MalConv ( https://github.com/endgameinc/ember/tree/master/malconv ). This sample is a wonderful resource to base your implementation on. However, note that this code is 2 years (i.e., a lifetime in ML) old, and does not precisely conform to the requirements of this project.\n",
    "\n",
    "Implementation: The model must be implemented in Python 3.x using TensorFlow (1.x or 2.x) and Keras, and needs to be coded and documented in a Jupyter Notebook. Additionaly, add textual description blocks to the notebook to document and explain the different parts of your code.\n",
    "\n",
    "Training: This model may take a long time to train on your personal computers (from 7-8 hours to a couple of days, depending on the config), unless you already have a powerful NVIDIA GPU (1080 TI or better). Alternatively, you can use the cloud platforms to speed up the training: Google Colab or AWS Sagemaker.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network Model on EMBER Malware Dataset:\n",
    "The EMBER dataset is a collection of features from PE files that serve as a benchmark dataset for researchers.\n",
    "In this notebook, the EMBER-2017 v2 dataset is used which contains features from 1.1 million PE files scanned in or before 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Extraction:\n",
    "To use the dataset in this notebook, simple download and upload didn't work as the URL to download the dataset is detected as untrused by Google. So, downloading the EMBER 2017 v2 dataset to Colab notebook using wget command and double unzipping it to get the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-18 19:54:43--  https://pubdata.endgame.com/ember/ember_dataset_2017_2.tar.bz2\n",
      "Resolving pubdata.endgame.com (pubdata.endgame.com)... 64.250.189.21\n",
      "Connecting to pubdata.endgame.com (pubdata.endgame.com)|64.250.189.21|:443... connected.\n",
      "WARNING: cannot verify pubdata.endgame.com's certificate, issued by ‘CN=Go Daddy Secure Certificate Authority - G2,OU=http://certs.godaddy.com/repository/,O=GoDaddy.com\\\\, Inc.,L=Scottsdale,ST=Arizona,C=US’:\n",
      "  Issued certificate has expired.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1751237573 (1.6G) [application/octet-stream]\n",
      "Saving to: ‘ember_dataset_2017_2.tar.bz2’\n",
      "\n",
      "ember_dataset_2017_ 100%[===================>]   1.63G   111MB/s    in 15s     \n",
      "\n",
      "2021-12-18 19:54:58 (110 MB/s) - ‘ember_dataset_2017_2.tar.bz2’ saved [1751237573/1751237573]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://pubdata.endgame.com/ember/ember_dataset_2017_2.tar.bz2 --no-check-certificate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompressing a .bz2 file\n",
    "!bzip2 -d ember_dataset_2017_2.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ember_2017_2/\n",
      "ember_2017_2/train_features_1.jsonl\n",
      "ember_2017_2/train_features_0.jsonl\n",
      "ember_2017_2/train_features_3.jsonl\n",
      "ember_2017_2/test_features.jsonl\n",
      "ember_2017_2/train_features_5.jsonl\n",
      "ember_2017_2/train_features_4.jsonl\n",
      "ember_2017_2/train_features_2.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Extracting from tar file\n",
    "!tar -xvf ember_dataset_2017_2.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the required dataset files are extracted.\n",
    "Now to work with the EMBER dataset, we need to clone its github repository:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
