{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify PE files as malware or benign. <br>\n",
    "**Dataset:**<br>\n",
    "EMBER-2017 v2- https://github.com/endgameinc/ember\n",
    "\n",
    "**Training:**<br>\n",
    "Training on peronal systems would take a very long time. For an octa core apple m1 silicon, training didn't complete in 7-8 hours.<br>\n",
    "Google colaboratory PRO provides a high RAM (~25GB) but even that crashes.<br>\n",
    "We used pickled and hierarchical data to prevent crashes as much as possible.<br>\n",
    "\n",
    "Hence, most of our processing was done on AWS Sagemaker.<br>\n",
    "We used an octacore processor with 32 GB of RAM for computations and 264GB RAM for Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMBER Malware Dataset:\n",
    "The EMBER dataset is a collection of features from PE files that serve as a benchmark dataset for researchers.<br>\n",
    "In this notebook, the EMBER-2017 v2 dataset is used which contains features from 1.1 million PE files scanned in or before 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-19 14:45:51--  https://pubdata.endgame.com/ember/ember_dataset_2017_2.tar.bz2\n",
      "Resolving pubdata.endgame.com (pubdata.endgame.com)... 64.250.189.21\n",
      "Connecting to pubdata.endgame.com (pubdata.endgame.com)|64.250.189.21|:443... connected.\n",
      "WARNING: cannot verify pubdata.endgame.com's certificate, issued by ‘CN=Go Daddy Secure Certificate Authority - G2,OU=http://certs.godaddy.com/repository/,O=GoDaddy.com\\\\, Inc.,L=Scottsdale,ST=Arizona,C=US’:\n",
      "  Issued certificate has expired.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1751237573 (1.6G) [application/octet-stream]\n",
      "Saving to: ‘ember_dataset_2017_2.tar.bz2’\n",
      "\n",
      "ember_dataset_2017_ 100%[===================>]   1.63G   110MB/s    in 15s     \n",
      "\n",
      "2021-12-19 14:46:07 (109 MB/s) - ‘ember_dataset_2017_2.tar.bz2’ saved [1751237573/1751237573]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://pubdata.endgame.com/ember/ember_dataset_2017_2.tar.bz2 --no-check-certificate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bzip2: Output file ember_dataset_2017_2.tar already exists.\n"
     ]
    }
   ],
   "source": [
    "# Decompressing a .bz2 file\n",
    "!bzip2 -d ember_dataset_2017_2.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ember_2017_2/\n",
      "ember_2017_2/train_features_1.jsonl\n",
      "ember_2017_2/train_features_0.jsonl\n",
      "ember_2017_2/train_features_3.jsonl\n",
      "ember_2017_2/test_features.jsonl\n",
      "ember_2017_2/train_features_5.jsonl\n",
      "ember_2017_2/train_features_4.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Extracting from tar file\n",
    "!tar -xvf ember_dataset_2017_2.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the required dataset files are extracted.\n",
    "Now we clone the Ember repo to process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ember'...\n",
      "remote: Enumerating objects: 266, done.\u001b[K\n",
      "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
      "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
      "remote: Total 266 (delta 32), reused 45 (delta 14), pack-reused 192\u001b[K\n",
      "Receiving objects: 100% (266/266), 11.36 MiB | 60.90 MiB/s, done.\n",
      "Resolving deltas: 100% (113/113), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/endgameinc/ember"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv ember ember-master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r ember-master/* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lief>=0.9.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (0.11.5)\n",
      "Requirement already satisfied: tqdm>=4.31.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.16.3 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (1.19.5)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (1.1.5)\n",
      "Requirement already satisfied: lightgbm>=2.2.3 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (3.3.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.3 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from -r requirements.txt (line 6)) (0.24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from pandas>=0.24.2->-r requirements.txt (line 4)) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from pandas>=0.24.2->-r requirements.txt (line 4)) (2021.1)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from lightgbm>=2.2.3->-r requirements.txt (line 5)) (1.5.3)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from lightgbm>=2.2.3->-r requirements.txt (line 5)) (0.36.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from scikit-learn>=0.20.3->-r requirements.txt (line 6)) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from scikit-learn>=0.20.3->-r requirements.txt (line 6)) (2.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas>=0.24.2->-r requirements.txt (line 4)) (1.15.0)\n",
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing ember.egg-info/PKG-INFO\n",
      "writing dependency_links to ember.egg-info/dependency_links.txt\n",
      "writing requirements to ember.egg-info/requires.txt\n",
      "writing top-level names to ember.egg-info/top_level.txt\n",
      "reading manifest file 'ember.egg-info/SOURCES.txt'\n",
      "writing manifest file 'ember.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/ember\n",
      "copying build/lib/ember/features.py -> build/bdist.linux-x86_64/egg/ember\n",
      "copying build/lib/ember/__init__.py -> build/bdist.linux-x86_64/egg/ember\n",
      "byte-compiling build/bdist.linux-x86_64/egg/ember/features.py to features.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/ember/__init__.py to __init__.cpython-36.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying ember.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying ember.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying ember.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying ember.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying ember.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "creating 'dist/ember-0.1.0-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing ember-0.1.0-py3.6.egg\n",
      "Removing /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/ember-0.1.0-py3.6.egg\n",
      "Copying ember-0.1.0-py3.6.egg to /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages\n",
      "ember 0.1.0 is already the active version in easy-install.pth\n",
      "\n",
      "Installed /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/ember-0.1.0-py3.6.egg\n",
      "Processing dependencies for ember==0.1.0\n",
      "Searching for scikit-learn==0.24.1\n",
      "Best match: scikit-learn 0.24.1\n",
      "Adding scikit-learn 0.24.1 to easy-install.pth file\n",
      "\n",
      "Using /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages\n",
      "Searching for lightgbm==3.3.1\n",
      "Best match: lightgbm 3.3.1\n",
      "Adding lightgbm 3.3.1 to easy-install.pth file\n",
      "\n",
      "Using /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages\n",
      "Searching for pandas==1.1.5\n",
      "Best match: pandas 1.1.5\n",
      "Adding pandas 1.1.5 to easy-install.pth file\n",
      "\n",
      "Using /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages\n",
      "Searching for numpy==1.19.5\n",
      "Best match: numpy 1.19.5\n",
      "Adding numpy 1.19.5 to easy-install.pth file\n",
      "Installing f2py script to /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/bin\n",
      "Installing f2py3 script to /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/bin\n",
      "Installing f2py3.6 script to /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/bin\n",
      "\n",
      "Using /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages\n",
      "Searching for tqdm==4.62.3\n",
      "Best match: tqdm 4.62.3\n",
      "Adding tqdm 4.62.3 to easy-install.pth file\n",
      "Installing tqdm script to /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/bin\n",
      "\n",
      "Using /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages\n",
      "Searching for lief==0.11.5\n",
      "Best match: lief 0.11.5\n",
      "Adding lief 0.11.5 to easy-install.pth file\n",
      "\n",
      "Using /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages\n",
      "Searching for scipy==1.5.3\n",
      "Best match: scipy 1.5.3\n",
      "Adding scipy 1.5.3 to easy-install.pth file\n",
      "\n",
      "Using /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages\n",
      "Searching for joblib==1.0.1\n",
      "Best match: joblib 1.0.1\n",
      "Adding joblib 1.0.1 to easy-install.pth file\n",
      "\n",
      "Using /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages\n",
      "Searching for threadpoolctl==2.1.0\n",
      "Best match: threadpoolctl 2.1.0\n",
      "Adding threadpoolctl 2.1.0 to easy-install.pth file\n",
      "\n",
      "Using /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages\n",
      "Searching for wheel==0.36.2\n",
      "Best match: wheel 0.36.2\n",
      "Adding wheel 0.36.2 to easy-install.pth file\n",
      "Installing wheel script to /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/bin\n",
      "\n",
      "Using /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages\n",
      "Searching for pytz==2021.1\n",
      "Best match: pytz 2021.1\n",
      "Adding pytz 2021.1 to easy-install.pth file\n",
      "\n",
      "Using /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages\n",
      "Searching for python-dateutil==2.8.1\n",
      "Best match: python-dateutil 2.8.1\n",
      "Adding python-dateutil 2.8.1 to easy-install.pth file\n",
      "\n",
      "Using /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages\n",
      "Searching for six==1.15.0\n",
      "Best match: six 1.15.0\n",
      "Adding six 1.15.0 to easy-install.pth file\n",
      "\n",
      "Using /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages\n",
      "Finished processing dependencies for ember==0.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "!python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ember"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ember.create_vectorized_features(\"/home/ec2-user/SageMaker/MalwareClassification/ember_2017_2/\")\n",
    "ember.create_metadata(\"/home/ec2-user/SageMaker/MalwareClassification/ember_2017_2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sha256</th>\n",
       "      <th>appeared</th>\n",
       "      <th>label</th>\n",
       "      <th>subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0abb4fda7d5b13801d63bee53e5e256be43e141faa077a...</td>\n",
       "      <td>2006-12</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d4206650743b3d519106dea10a38a55c30467c3d9f7875...</td>\n",
       "      <td>2006-12</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c9cafff8a596ba8a80bafb4ba8ae6f2ef3329d95b85f15...</td>\n",
       "      <td>2007-01</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7f513818bcc276c531af2e641c597744da807e21cc1160...</td>\n",
       "      <td>2007-02</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ca65e1c387a4cc9e7d8a8ce12bf1bcf9f534c9032b9d95...</td>\n",
       "      <td>2007-02</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sha256 appeared  label subset\n",
       "0  0abb4fda7d5b13801d63bee53e5e256be43e141faa077a...  2006-12      0  train\n",
       "1  d4206650743b3d519106dea10a38a55c30467c3d9f7875...  2006-12      0  train\n",
       "2  c9cafff8a596ba8a80bafb4ba8ae6f2ef3329d95b85f15...  2007-01      0  train\n",
       "3  7f513818bcc276c531af2e641c597744da807e21cc1160...  2007-02      0  train\n",
       "4  ca65e1c387a4cc9e7d8a8ce12bf1bcf9f534c9032b9d95...  2007-02      0  train"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"/home/ec2-user/SageMaker/MalwareClassification/ember_2017_2/\"\n",
    "emberdf = ember.read_metadata(data_path)\n",
    "emberdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: EMBER feature version 2 were computed using lief version 0.9.0-\n",
      "WARNING:   lief version 0.11.5-37bc2c9 found instead. There may be slight inconsistencies\n",
      "WARNING:   in the feature calculations.\n"
     ]
    }
   ],
   "source": [
    "X_train0, y_train0, X_test0, y_test0 = ember.read_vectorized_features(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([[1.4676122e-02, 4.2218715e-03, 3.9226813e-03, ..., 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [7.2290748e-02, 1.4057922e-02, 1.1037279e-02, ..., 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [1.8452372e-01, 3.1307504e-02, 5.6928140e-03, ..., 4.4229600e+05,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        ...,\n",
       "        [3.2558188e-01, 5.2042645e-03, 4.0974934e-03, ..., 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [5.0731432e-01, 9.9041909e-03, 5.1698429e-03, ..., 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [6.8576080e-01, 4.2310823e-03, 4.0683481e-03, ..., 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((900000, 2381), (900000,), (200000, 2381), (200000,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of the dataset\n",
    "X_train0.shape, y_train0.shape, X_test0.shape, y_test0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900000, 2381)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900000,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing:\n",
    "It is known that the EMBER train dataset has three sample categories, namels unlabled, benign and malicious.\n",
    "They are represented as -1, 0 and 1 respectively.\n",
    "\n",
    "But it can be seen that the test dataset has only benign and malicious samples.\n",
    "Ignoring the unlabled samples from the train dataset for the better performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((900000, 2381), (900000, 1))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Creating dataframes of X_train & y_train\n",
    "X_train0 = pd.DataFrame(X_train0)\n",
    "y_train0 = pd.DataFrame(y_train0)\n",
    "X_train0.shape, y_train0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0., -1.,  1.], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Unique labels in the train dataset \n",
    "y_train0[0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((900000, 2382), (900000, 1))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining features and lables of train dataset\n",
    "X_train0[2381] = y_train0[0]\n",
    "X_train0.shape, y_train0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2372</th>\n",
       "      <th>2373</th>\n",
       "      <th>2374</th>\n",
       "      <th>2375</th>\n",
       "      <th>2376</th>\n",
       "      <th>2377</th>\n",
       "      <th>2378</th>\n",
       "      <th>2379</th>\n",
       "      <th>2380</th>\n",
       "      <th>2381</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014676</td>\n",
       "      <td>0.004222</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.004029</td>\n",
       "      <td>0.004007</td>\n",
       "      <td>0.003775</td>\n",
       "      <td>0.003825</td>\n",
       "      <td>0.003887</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>0.003804</td>\n",
       "      <td>...</td>\n",
       "      <td>35240.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.072291</td>\n",
       "      <td>0.014058</td>\n",
       "      <td>0.011037</td>\n",
       "      <td>0.010413</td>\n",
       "      <td>0.009210</td>\n",
       "      <td>0.007145</td>\n",
       "      <td>0.007679</td>\n",
       "      <td>0.007695</td>\n",
       "      <td>0.008287</td>\n",
       "      <td>0.005417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.184524</td>\n",
       "      <td>0.031308</td>\n",
       "      <td>0.005693</td>\n",
       "      <td>0.005959</td>\n",
       "      <td>0.008144</td>\n",
       "      <td>0.003512</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.008550</td>\n",
       "      <td>0.009141</td>\n",
       "      <td>0.001791</td>\n",
       "      <td>...</td>\n",
       "      <td>92936.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>2604.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>442296.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008964</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.003925</td>\n",
       "      <td>0.003936</td>\n",
       "      <td>0.004037</td>\n",
       "      <td>0.003878</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>0.003939</td>\n",
       "      <td>0.003834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.020401</td>\n",
       "      <td>0.005213</td>\n",
       "      <td>0.004519</td>\n",
       "      <td>0.004097</td>\n",
       "      <td>0.004240</td>\n",
       "      <td>0.004029</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.003780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899995</th>\n",
       "      <td>0.245216</td>\n",
       "      <td>0.018520</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.003457</td>\n",
       "      <td>0.005346</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>0.002744</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.005196</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>397616.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899996</th>\n",
       "      <td>0.526616</td>\n",
       "      <td>0.008944</td>\n",
       "      <td>0.007258</td>\n",
       "      <td>0.004506</td>\n",
       "      <td>0.006111</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>0.001821</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899997</th>\n",
       "      <td>0.325582</td>\n",
       "      <td>0.005204</td>\n",
       "      <td>0.004097</td>\n",
       "      <td>0.003560</td>\n",
       "      <td>0.006873</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.004077</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>0.007007</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>544.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899998</th>\n",
       "      <td>0.507314</td>\n",
       "      <td>0.009904</td>\n",
       "      <td>0.005170</td>\n",
       "      <td>0.003962</td>\n",
       "      <td>0.006889</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>0.003128</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.002570</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899999</th>\n",
       "      <td>0.685761</td>\n",
       "      <td>0.004231</td>\n",
       "      <td>0.004068</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>0.004394</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900000 rows × 2382 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6     \\\n",
       "0       0.014676  0.004222  0.003923  0.004029  0.004007  0.003775  0.003825   \n",
       "1       0.072291  0.014058  0.011037  0.010413  0.009210  0.007145  0.007679   \n",
       "2       0.184524  0.031308  0.005693  0.005959  0.008144  0.003512  0.005786   \n",
       "3       0.008964  0.004055  0.003925  0.003936  0.004037  0.003878  0.003847   \n",
       "4       0.020401  0.005213  0.004519  0.004097  0.004240  0.004029  0.003785   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "899995  0.245216  0.018520  0.003637  0.003457  0.005346  0.002167  0.002744   \n",
       "899996  0.526616  0.008944  0.007258  0.004506  0.006111  0.001484  0.001174   \n",
       "899997  0.325582  0.005204  0.004097  0.003560  0.006873  0.001758  0.004077   \n",
       "899998  0.507314  0.009904  0.005170  0.003962  0.006889  0.002890  0.003128   \n",
       "899999  0.685761  0.004231  0.004068  0.002441  0.004394  0.000488  0.001302   \n",
       "\n",
       "            7         8         9     ...     2372   2373   2374    2375  \\\n",
       "0       0.003887  0.004153  0.003804  ...  35240.0    0.0    0.0   660.0   \n",
       "1       0.007695  0.008287  0.005417  ...      0.0    0.0    0.0     0.0   \n",
       "2       0.008550  0.009141  0.001791  ...  92936.0  408.0  608.0  2604.0   \n",
       "3       0.003946  0.003939  0.003834  ...      0.0    0.0    0.0     0.0   \n",
       "4       0.004593  0.004875  0.003780  ...      0.0    0.0    0.0   520.0   \n",
       "...          ...       ...       ...  ...      ...    ...    ...     ...   \n",
       "899995  0.003652  0.005196  0.001740  ...      0.0    0.0    0.0   184.0   \n",
       "899996  0.001821  0.002631  0.000728  ...      0.0   32.0  552.0   132.0   \n",
       "899997  0.005501  0.007007  0.001392  ...      0.0   32.0  568.0   544.0   \n",
       "899998  0.002778  0.002570  0.002144  ...      0.0   32.0  552.0   180.0   \n",
       "899999  0.000000  0.003092  0.000976  ...      0.0    0.0    0.0     0.0   \n",
       "\n",
       "            2376   2377      2378  2379  2380  2381  \n",
       "0        32768.0    0.0       0.0   0.0   0.0   0.0  \n",
       "1            0.0    0.0       0.0   0.0   0.0   0.0  \n",
       "2         4096.0  224.0  442296.0   0.0   0.0   0.0  \n",
       "3            0.0    0.0       0.0   0.0   0.0   0.0  \n",
       "4         4096.0    0.0       0.0   0.0   0.0   0.0  \n",
       "...          ...    ...       ...   ...   ...   ...  \n",
       "899995  397616.0    0.0       0.0   0.0   0.0   1.0  \n",
       "899996    4096.0    0.0       0.0   0.0   0.0   1.0  \n",
       "899997    4096.0    0.0       0.0   0.0   0.0  -1.0  \n",
       "899998    4096.0    0.0       0.0   0.0   0.0   1.0  \n",
       "899999       0.0    0.0       0.0   0.0   0.0   1.0  \n",
       "\n",
       "[900000 rows x 2382 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the presence of unique lables in the combined dataframe\n",
    "X_train0[2381].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the unlabeled rows from the dataframe\n",
    "\n",
    "X_train0.drop(X_train0[(X_train0[2381] == -1)].index, inplace = True)\n",
    "y_train0.drop(y_train0[(y_train0[0] == -1)].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((600000, 2381), (600000, 1))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train0.shape, y_train0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[2381] not found in axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-0e6da049afd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#reconstructing the X_train dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2381\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_train0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4172\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4173\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4174\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4175\u001b[0m         )\n\u001b[1;32m   4176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3887\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3888\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3889\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3891\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3921\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3922\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3923\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3924\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5286\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5287\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5288\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '[2381] not found in axis'"
     ]
    }
   ],
   "source": [
    "#reconstructing the X_train dataframe\n",
    "X_train0.drop([2381], axis =1, inplace=True)\n",
    "X_train0.shape, y_train0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is huge and takes lot to time for vectorizing and creating metadata for every runtime execution.<br>\n",
    "So, we created pickle files for training and testing samples to store them persistently.<br>\n",
    "By downloading and storing these pickle files, we avoid the execution of the former lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-b3eceae4922d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Pickling the datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./X_train.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./y_train.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./X_test.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./y_test.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(self, path, compression, protocol)\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2676\u001b[0;31m         \u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2678\u001b[0m     def to_clipboard(\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(obj, filepath_or_buffer, compression, protocol)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Pickling the datasets\n",
    "pd.DataFrame(X_train0).to_pickle(\"./X_train.pkl\")\n",
    "pd.DataFrame(y_train0).to_pickle(\"./y_train.pkl\")\n",
    "pd.DataFrame(X_test0).to_pickle(\"./X_test.pkl\")\n",
    "pd.DataFrame(y_test0).to_pickle(\"./y_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './X_train.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-7fccd4c5bf98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Extracting training data from pickle files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_trainp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./X_train.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_trainp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./y_train.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcompression\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"infer\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# 1) try standard library Pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './X_train.pkl'"
     ]
    }
   ],
   "source": [
    "# Extracting training data from pickle files\n",
    "X_trainp = pd.read_pickle(\"./X_train.pkl\")\n",
    "y_trainp = pd.read_pickle(\"./y_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting testing data from pickle files\n",
    "X_testp =pd.read_pickle(\"./X_test.pkl\")\n",
    "y_testp = pd.read_pickle(\"./y_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((600000, 2381), (600000, 1), (200000, 2381), (200000, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shape of the dataset\n",
    "X_trainp.shape, y_trainp.shape, X_testp.shape, y_testp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we noticed that the above lines of code used around 25GB RAM.\n",
    "So, even though the datasets are pickled, the RAM crashes.\n",
    "Hence, the alternative for this is to create HDF5 files.\n",
    "The h5py package is a Pythonic interface to the HDF5 binary data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Loading X_train data to HDF5 file\n",
    "h50 = h5py.File('X_train0.h5', 'w')\n",
    "h50.create_dataset('X_train0', data=X_train0)\n",
    "h50.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading y_train data to HDF5 file\n",
    "h51 = h5py.File('y_train0.h5', 'w')\n",
    "h51.create_dataset('y_train0', data=y_train0)\n",
    "h51.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading X_test data to HDF5 file\n",
    "h52 = h5py.File('X_test0.h5', 'w')\n",
    "h52.create_dataset('X_test0', data=X_test0)\n",
    "h52.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading y_test data to HDF5 file\n",
    "h53 = h5py.File('y_test0.h5', 'w')\n",
    "h53.create_dataset('y_test0', data=y_test0)\n",
    "h53.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600000, 2381)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading the X_train data from h5 files \n",
    "import h5py\n",
    "Xh5 = h5py.File('./X_train0.h5','r')\n",
    "X_train = Xh5['X_train0']\n",
    "X_train.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600000, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading y_train data from h5 files\n",
    "import h5py\n",
    "yh5 = h5py.File('./y_train0.h5','r')\n",
    "y_train = yh5['y_train0']\n",
    "y_train.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 2381)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading X_test data from h5 files\n",
    "import h5py\n",
    "Xth5 = h5py.File('./X_test0.h5','r')\n",
    "X_test = Xth5['X_test0']\n",
    "X_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading y_test data from h5 files\n",
    "import h5py\n",
    "yth5 = h5py.File('./y_test0.h5','r')\n",
    "y_test = yth5['y_test0']\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The features of this dataset are scaled on different scalars.\n",
    "We picked RobustScalar to do the feature scaling.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the features inorder to improve the performance of the model\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "rs = RobustScaler()\n",
    "Xtrain_rs = rs.fit_transform(X_train)\n",
    "Xtest_rs = rs.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading scaled X_train data to HDF5 file\n",
    "h54 = h5py.File('Xtrain_rs.h5', 'w')\n",
    "h54.create_dataset('Xtrain_rs', data=Xtrain_rs)\n",
    "h54.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading scaled X_test data to HDF5 file\n",
    "h55 = h5py.File('Xtest_rs.h5', 'w')\n",
    "h55.create_dataset('Xtest_rs', data=Xtest_rs)\n",
    "h55.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600000, 2381)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading Xtrain_rs data from h5 files\n",
    "import h5py\n",
    "Xrsh5 = h5py.File('./Xtrain_rs.h5','r')\n",
    "Xtrain_rs = Xrsh5['Xtrain_rs']\n",
    "Xtrain_rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 2381)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading Xtest_rs data from h5 files\n",
    "import h5py\n",
    "Xtrsh5 = h5py.File('./Xtest_rs.h5','r')\n",
    "Xtest_rs = Xtrsh5['Xtest_rs']\n",
    "Xtest_rs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Design & Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import sklearn.ensemble as ske"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing results of the Classification Algos\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm comparison\n",
    "algorithms = {\n",
    "    \"DecisionTree\": tree.DecisionTreeClassifier(max_depth=10),\n",
    "    \"RandomForest\": ske.RandomForestClassifier(n_estimators=100),\n",
    "    \"AdaBoost\": ske.AdaBoostClassifier(n_estimators=100),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree:\n",
      "DecisionTree : 96.37%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating Decision Tree:\")\n",
    "\n",
    "decisionTree = algorithms['DecisionTree']\n",
    "decisionTree.fit(X_train, y_train)\n",
    "decisionTreeScore = decisionTree.score(X_test, y_test)\n",
    "print(f\"DecisionTree : {decisionTreeScore*100}%\")\n",
    "results['DecisionTree'] = decisionTreeScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/ipykernel/__main__.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-24849a869e7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrandomForest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RandomForest'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrandomForest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mrandomForestScore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomForest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"RandomForest : {randomForestScore*100}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    391\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 393\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    167\u001b[0m                                                         indices=indices)\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    903\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    387\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating Random Forest:\")\n",
    "\n",
    "randomForest = algorithms['RandomForest']\n",
    "randomForest.fit(X_train, y_train)\n",
    "randomForestScore = randomForest.score(X_test, y_test)\n",
    "print(f\"RandomForest : {randomForestScore*100}%\")\n",
    "results['RandomForest'] = randomForestScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = y_train.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-d5f89f900b32>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-d5f89f900b32>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    print(f\"adaBoost : {adaBoostScore*100}%\")\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating Ada Boost:\")\n",
    "\n",
    "adaBoost = algorithms['AdaBoost']\n",
    "adaBoost.fit(X_train, y_train)\n",
    "adaBoostScore = adaBoost.score(X_test, y_test[0])\n",
    "print(f\"adaBoost : {adaBoostScore*100}%\")\n",
    "results['adaBoost'] = adaBoostScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Winner algorithm is RandomForest with a 86.489% success\n"
     ]
    }
   ],
   "source": [
    "winner = max(results, key=results.get)\n",
    "print(f'\\nWinner algorithm is {winner} with a {results[winner]*100}% success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the folder to store the features and classifier.\n",
    "if not os.path.exists('classifier'):\n",
    "    os.makedirs('classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving algorithm and feature list in classifier directory...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./classifier/classifier.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the algorithm and the feature list for later predictions\n",
    "print('Saving algorithm and feature list in classifier directory...')\n",
    "joblib.dump(algorithms[winner], './classifier/classifier.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-19 09:47:29--  https://repo.anaconda.com/archive/Anaconda3-2020.02-Windows-x86_64.exe\n",
      "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.131.3, 104.16.130.3, 2606:4700::6810:8203, ...\n",
      "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.131.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 488908696 (466M) [application/octet-stream]\n",
      "Saving to: ‘Anaconda3-2020.02-Windows-x86_64.exe’\n",
      "\n",
      "Anaconda3-2020.02-W 100%[===================>] 466.26M   129MB/s    in 3.7s    \n",
      "\n",
      "2021-12-19 09:47:33 (125 MB/s) - ‘Anaconda3-2020.02-Windows-x86_64.exe’ saved [488908696/488908696]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://repo.anaconda.com/archive/Anaconda3-2020.02-Windows-x86_64.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictPE(pe):\n",
    "    import ember\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "    from sklearn.preprocessing import RobustScaler\n",
    "    rs = RobustScaler()\n",
    "\n",
    "    #opening the downloaded PE file\n",
    "    testpe = open(pe, \"rb\").read()\n",
    "\n",
    "    #Feature extractor class of the ember project \n",
    "    extract = ember.PEFeatureExtractor()\n",
    "\n",
    "    #vectorizing the extracted features\n",
    "    data = extract.feature_vector(testpe)\n",
    "    scaled_data = rs.fit_transform([data])\n",
    "    Xdata = np.reshape(scaled_data,(1, 2381))\n",
    "    \n",
    "    #Load classifier and Predict\n",
    "    clf = joblib.load('./classifier/classifier.pkl')\n",
    "    res = clf.predict(Xdata)\n",
    "\n",
    "    prediction = ['malicious', 'legitimate'][res]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: EMBER feature version 2 were computed using lief version 0.9.0-\n",
      "WARNING:   lief version 0.11.5-37bc2c9 found instead. There may be slight inconsistencies\n",
      "WARNING:   in the feature calculations.\n"
     ]
    }
   ],
   "source": [
    "prediction = testPE(\"Anaconda3-2020.02-Windows-x86_64.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
